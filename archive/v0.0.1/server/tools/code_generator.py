"""
Code Generator Tool for CLIF MCP Server
Generates reproducible analysis scripts for multi-site validation
"""

import json
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import textwrap


class CodeGenerator:
    def __init__(self):
        self.analysis_history = []
        self.templates = self._load_templates()
        
    def _load_templates(self) -> Dict[str, str]:
        """Load code generation templates"""
        return {
            'python_header': self._python_header_template(),
            'r_header': self._r_header_template(),
            'cohort_builder_python': self._cohort_builder_python_template(),
            'cohort_builder_r': self._cohort_builder_r_template(),
            'outcomes_analysis_python': self._outcomes_analysis_python_template(),
            'outcomes_analysis_r': self._outcomes_analysis_r_template(),
            'visualization_python': self._visualization_python_template(),
            'visualization_r': self._visualization_r_template()
        }
    
    def store_analysis(self, analysis_results: Dict[str, Any]):
        """Store analysis results for code generation"""
        self.analysis_history.append({
            'timestamp': datetime.now().isoformat(),
            'results': analysis_results
        })
    
    def generate_code(self, analysis_type: str, language: str = 'python',
                     include_visualizations: bool = True, 
                     output_format: str = 'script') -> str:
        """Generate analysis code based on stored analyses"""
        
        if language == 'python':
            return self._generate_python_code(analysis_type, include_visualizations)
        elif language == 'r':
            return self._generate_r_code(analysis_type, include_visualizations)
        else:
            raise ValueError(f"Unsupported language: {language}")
    
    def generate_regression_code(self, config: Dict[str, Any], language: str = 'python') -> str:
        """Generate regression analysis code"""
        
        if language == 'python':
            return self._generate_python_regression(config)
        elif language == 'r':
            return self._generate_r_regression(config)
        else:
            raise ValueError(f"Unsupported language: {language}")
    
    def _generate_python_code(self, analysis_type: str, 
                             include_visualizations: bool) -> str:
        """Generate Python analysis script"""
        
        code_parts = [self.templates['python_header']]
        
        # Add cohort building code
        if analysis_type in ['cohort_analysis', 'full_analysis']:
            code_parts.append(self.templates['cohort_builder_python'])
        
        # Add outcomes analysis code
        if analysis_type in ['outcomes_analysis', 'full_analysis']:
            code_parts.append(self.templates['outcomes_analysis_python'])
        
        # Add visualization code
        if include_visualizations:
            code_parts.append(self.templates['visualization_python'])
        
        # Add main execution block
        code_parts.append(self._python_main_block())
        
        return '\n\n'.join(code_parts)
    
    def _generate_r_code(self, analysis_type: str, 
                        include_visualizations: bool) -> str:
        """Generate R analysis script"""
        
        code_parts = [self.templates['r_header']]
        
        # Add cohort building code
        if analysis_type in ['cohort_analysis', 'full_analysis']:
            code_parts.append(self.templates['cohort_builder_r'])
        
        # Add outcomes analysis code
        if analysis_type in ['outcomes_analysis', 'full_analysis']:
            code_parts.append(self.templates['outcomes_analysis_r'])
        
        # Add visualization code
        if include_visualizations:
            code_parts.append(self.templates['visualization_r'])
        
        return '\n\n'.join(code_parts)
    
    def _python_header_template(self) -> str:
        return textwrap.dedent('''
        """
        CLIF Outcomes Analysis Script
        Generated by CLIF MCP Server
        
        This script performs reproducible clinical outcomes analysis on CLIF datasets.
        Designed for multi-site validation while preserving data privacy.
        """
        
        import pandas as pd
        import numpy as np
        from pathlib import Path
        import json
        from datetime import datetime, timedelta
        import scipy.stats as stats
        from statsmodels.stats.proportion import proportions_ztest, proportion_confint
        import matplotlib.pyplot as plt
        import seaborn as sns
        import warnings
        warnings.filterwarnings('ignore')
        
        # Configuration
        DATA_PATH = Path("./data")  # Update to your CLIF data directory
        OUTPUT_PATH = Path("./results")
        OUTPUT_PATH.mkdir(exist_ok=True)
        
        # Set random seed for reproducibility
        np.random.seed(42)
        ''')
    
    def _r_header_template(self) -> str:
        return textwrap.dedent('''
        # CLIF Outcomes Analysis Script
        # Generated by CLIF MCP Server
        # 
        # This script performs reproducible clinical outcomes analysis on CLIF datasets.
        # Designed for multi-site validation while preserving data privacy.
        
        # Load required libraries
        library(tidyverse)
        library(lubridate)
        library(survival)
        library(ggplot2)
        library(tableone)
        
        # Configuration
        DATA_PATH <- "./data"  # Update to your CLIF data directory
        OUTPUT_PATH <- "./results"
        dir.create(OUTPUT_PATH, showWarnings = FALSE)
        
        # Set random seed for reproducibility
        set.seed(42)
        ''')
    
    def _cohort_builder_python_template(self) -> str:
        return textwrap.dedent('''
        class CohortBuilder:
            """Build patient cohorts based on clinical criteria"""
            
            def __init__(self, data_path):
                self.data_path = Path(data_path)
                self.tables = self.load_tables()
            
            def load_tables(self):
                """Load CLIF tables from CSV files"""
                tables = {}
                for table_name in ['patient', 'hospitalization', 'adt', 
                                 'respiratory_support', 'medication_administration']:
                    file_path = self.data_path / f"{table_name}.csv"
                    if file_path.exists():
                        df = pd.read_csv(file_path)
                        # Parse datetime columns
                        for col in df.columns:
                            if 'dttm' in col or 'date' in col:
                                df[col] = pd.to_datetime(df[col], errors='coerce')
                        tables[table_name] = df
                return tables
            
            def build_cohort(self, criteria):
                """Build cohort based on criteria"""
                cohort = self.tables['hospitalization'].copy()
                
                # Age filter
                if 'age_range' in criteria:
                    age_min = criteria['age_range'].get('min', 0)
                    age_max = criteria['age_range'].get('max', 120)
                    cohort = cohort[
                        (cohort['age_at_admission'] >= age_min) & 
                        (cohort['age_at_admission'] <= age_max)
                    ]
                
                # Mechanical ventilation filter
                if criteria.get('require_mechanical_ventilation', False):
                    vent_ids = self.get_ventilated_patients()
                    cohort = cohort[cohort['hospitalization_id'].isin(vent_ids)]
                
                return cohort
            
            def get_ventilated_patients(self):
                """Get mechanically ventilated patients"""
                resp = self.tables['respiratory_support']
                vent_ids = resp[
                    resp['device_category'] == 'Invasive Mechanical Ventilation'
                ]['hospitalization_id'].unique()
                return list(vent_ids)
        ''')
    
    def _cohort_builder_r_template(self) -> str:
        return textwrap.dedent('''
        # Cohort Builder Functions
        
        load_clif_tables <- function(data_path) {
          tables <- list()
          
          # Load each CLIF table
          for (table_name in c("patient", "hospitalization", "adt", 
                              "respiratory_support", "medication_administration")) {
            file_path <- file.path(data_path, paste0(table_name, ".csv"))
            if (file.exists(file_path)) {
              df <- read_csv(file_path, show_col_types = FALSE)
              # Parse datetime columns
              datetime_cols <- names(df)[grepl("dttm|date", names(df))]
              df <- df %>%
                mutate(across(all_of(datetime_cols), ~ymd_hms(.)))
              tables[[table_name]] <- df
            }
          }
          
          return(tables)
        }
        
        build_cohort <- function(tables, criteria) {
          cohort <- tables$hospitalization
          
          # Age filter
          if (!is.null(criteria$age_range)) {
            age_min <- criteria$age_range$min %||% 0
            age_max <- criteria$age_range$max %||% 120
            cohort <- cohort %>%
              filter(age_at_admission >= age_min & age_at_admission <= age_max)
          }
          
          # Mechanical ventilation filter
          if (isTRUE(criteria$require_mechanical_ventilation)) {
            vent_ids <- tables$respiratory_support %>%
              filter(device_category == "Invasive Mechanical Ventilation") %>%
              pull(hospitalization_id) %>%
              unique()
            
            cohort <- cohort %>%
              filter(hospitalization_id %in% vent_ids)
          }
          
          return(cohort)
        }
        ''')
    
    def _outcomes_analysis_python_template(self) -> str:
        return textwrap.dedent('''
        class OutcomesAnalyzer:
            """Analyze clinical outcomes"""
            
            def __init__(self, tables):
                self.tables = tables
            
            def analyze_mortality(self, cohort):
                """Calculate mortality rate with confidence interval"""
                mortality = (cohort['discharge_disposition'] == 'Expired').astype(int)
                n_deaths = mortality.sum()
                n_total = len(cohort)
                
                # Wilson confidence interval
                ci_low, ci_high = proportion_confint(n_deaths, n_total, method='wilson')
                
                return {
                    'rate': mortality.mean(),
                    'count': n_deaths,
                    'total': n_total,
                    'ci_95': (ci_low, ci_high)
                }
            
            def analyze_icu_los(self, cohort):
                """Calculate ICU length of stay statistics"""
                adt = self.tables['adt']
                
                icu_los = []
                for hosp_id in cohort['hospitalization_id']:
                    icu_stays = adt[
                        (adt['hospitalization_id'] == hosp_id) & 
                        (adt['location_category'] == 'ICU')
                    ]
                    
                    if not icu_stays.empty:
                        total_hours = 0
                        for _, stay in icu_stays.iterrows():
                            duration = stay['out_dttm'] - stay['in_dttm']
                            total_hours += duration.total_seconds() / 3600
                        icu_los.append(total_hours / 24)  # Convert to days
                
                icu_los = pd.Series(icu_los)
                
                return {
                    'mean': icu_los.mean(),
                    'median': icu_los.median(),
                    'q1': icu_los.quantile(0.25),
                    'q3': icu_los.quantile(0.75),
                    'min': icu_los.min(),
                    'max': icu_los.max(),
                    'n': len(icu_los)
                }
            
            def compare_groups(self, group1, group2, outcome='mortality'):
                """Compare outcomes between two groups"""
                if outcome == 'mortality':
                    mort1 = (group1['discharge_disposition'] == 'Expired')
                    mort2 = (group2['discharge_disposition'] == 'Expired')
                    
                    # Proportions test
                    n1, n2 = len(group1), len(group2)
                    x1, x2 = mort1.sum(), mort2.sum()
                    
                    stat, pval = proportions_ztest([x1, x2], [n1, n2])
                    
                    return {
                        'group1_rate': mort1.mean(),
                        'group2_rate': mort2.mean(),
                        'risk_difference': mort1.mean() - mort2.mean(),
                        'p_value': pval
                    }
        ''')
    
    def _outcomes_analysis_r_template(self) -> str:
        return textwrap.dedent('''
        # Outcomes Analysis Functions
        
        analyze_mortality <- function(cohort) {
          mortality <- cohort %>%
            mutate(died = discharge_disposition == "Expired") %>%
            summarise(
              n_deaths = sum(died),
              n_total = n(),
              rate = mean(died)
            )
          
          # Wilson confidence interval
          ci <- prop.test(mortality$n_deaths, mortality$n_total)$conf.int
          
          return(list(
            rate = mortality$rate,
            count = mortality$n_deaths,
            total = mortality$n_total,
            ci_95 = c(ci[1], ci[2])
          ))
        }
        
        analyze_icu_los <- function(cohort, tables) {
          adt <- tables$adt
          
          icu_los <- cohort %>%
            left_join(
              adt %>%
                filter(location_category == "ICU") %>%
                group_by(hospitalization_id) %>%
                summarise(
                  icu_hours = sum(as.numeric(
                    difftime(out_dttm, in_dttm, units = "hours")
                  ))
                ),
              by = "hospitalization_id"
            ) %>%
            mutate(icu_days = icu_hours / 24) %>%
            filter(!is.na(icu_days))
          
          return(list(
            mean = mean(icu_los$icu_days),
            median = median(icu_los$icu_days),
            q1 = quantile(icu_los$icu_days, 0.25),
            q3 = quantile(icu_los$icu_days, 0.75),
            min = min(icu_los$icu_days),
            max = max(icu_los$icu_days),
            n = nrow(icu_los)
          ))
        }
        
        compare_groups <- function(group1, group2, outcome = "mortality") {
          if (outcome == "mortality") {
            mort1 <- sum(group1$discharge_disposition == "Expired")
            mort2 <- sum(group2$discharge_disposition == "Expired")
            n1 <- nrow(group1)
            n2 <- nrow(group2)
            
            # Proportions test
            test_result <- prop.test(c(mort1, mort2), c(n1, n2))
            
            return(list(
              group1_rate = mort1 / n1,
              group2_rate = mort2 / n2,
              risk_difference = (mort1 / n1) - (mort2 / n2),
              p_value = test_result$p.value
            ))
          }
        }
        ''')
    
    def _visualization_python_template(self) -> str:
        return textwrap.dedent('''
        def create_outcomes_visualizations(results, output_path):
            """Create standard outcomes visualizations"""
            
            # Set style
            sns.set_style("whitegrid")
            plt.rcParams['figure.figsize'] = (10, 6)
            
            # Mortality comparison plot
            if 'mortality_comparison' in results:
                fig, ax = plt.subplots()
                
                groups = list(results['mortality_comparison'].keys())
                rates = [results['mortality_comparison'][g]['rate'] for g in groups]
                cis = [results['mortality_comparison'][g]['ci_95'] for g in groups]
                
                # Plot rates with confidence intervals
                x = range(len(groups))
                ax.bar(x, rates, yerr=[[r - ci[0] for r, ci in zip(rates, cis)],
                                      [ci[1] - r for r, ci in zip(rates, cis)]],
                      capsize=5, alpha=0.7)
                
                ax.set_xticks(x)
                ax.set_xticklabels(groups)
                ax.set_ylabel('Mortality Rate')
                ax.set_title('Mortality Rates by Group')
                ax.set_ylim(0, max(rates) * 1.3)
                
                # Add rate labels
                for i, (rate, ci) in enumerate(zip(rates, cis)):
                    ax.text(i, rate + 0.01, f'{rate:.1%}', ha='center')
                
                plt.tight_layout()
                plt.savefig(output_path / 'mortality_comparison.png', dpi=300)
                plt.close()
            
            # ICU LOS distribution plot
            if 'icu_los_distribution' in results:
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                
                los_data = results['icu_los_distribution']
                
                # Histogram
                ax1.hist(los_data, bins=30, edgecolor='black', alpha=0.7)
                ax1.axvline(np.mean(los_data), color='red', linestyle='--', 
                          label=f'Mean: {np.mean(los_data):.1f} days')
                ax1.axvline(np.median(los_data), color='green', linestyle='--',
                          label=f'Median: {np.median(los_data):.1f} days')
                ax1.set_xlabel('ICU Length of Stay (days)')
                ax1.set_ylabel('Count')
                ax1.set_title('ICU Length of Stay Distribution')
                ax1.legend()
                
                # Box plot
                ax2.boxplot(los_data, vert=True)
                ax2.set_ylabel('ICU Length of Stay (days)')
                ax2.set_title('ICU LOS Box Plot')
                
                plt.tight_layout()
                plt.savefig(output_path / 'icu_los_distribution.png', dpi=300)
                plt.close()
            
            print(f"Visualizations saved to {output_path}")
        ''')
    
    def _visualization_r_template(self) -> str:
        return textwrap.dedent('''
        # Visualization Functions
        
        create_outcomes_visualizations <- function(results, output_path) {
          # Mortality comparison plot
          if ("mortality_comparison" %in% names(results)) {
            mort_data <- results$mortality_comparison %>%
              bind_rows(.id = "group") %>%
              mutate(
                lower_ci = ci_95[1],
                upper_ci = ci_95[2]
              )
            
            p1 <- ggplot(mort_data, aes(x = group, y = rate)) +
              geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
              geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                          width = 0.2, size = 1) +
              geom_text(aes(label = scales::percent(rate, accuracy = 0.1)),
                       vjust = -0.5) +
              scale_y_continuous(labels = scales::percent) +
              labs(title = "Mortality Rates by Group",
                   x = "Group",
                   y = "Mortality Rate") +
              theme_minimal()
            
            ggsave(file.path(output_path, "mortality_comparison.png"), 
                   p1, width = 10, height = 6, dpi = 300)
          }
          
          # ICU LOS distribution plot
          if ("icu_los_distribution" %in% names(results)) {
            los_data <- data.frame(los = results$icu_los_distribution)
            
            p2 <- ggplot(los_data, aes(x = los)) +
              geom_histogram(bins = 30, fill = "steelblue", 
                           color = "black", alpha = 0.7) +
              geom_vline(aes(xintercept = mean(los)), 
                        color = "red", linetype = "dashed", size = 1) +
              geom_vline(aes(xintercept = median(los)), 
                        color = "green", linetype = "dashed", size = 1) +
              labs(title = "ICU Length of Stay Distribution",
                   x = "ICU Length of Stay (days)",
                   y = "Count") +
              theme_minimal()
            
            ggsave(file.path(output_path, "icu_los_distribution.png"), 
                   p2, width = 10, height = 6, dpi = 300)
            
            # Box plot
            p3 <- ggplot(los_data, aes(y = los)) +
              geom_boxplot(fill = "steelblue", alpha = 0.7) +
              labs(title = "ICU Length of Stay Box Plot",
                   y = "ICU Length of Stay (days)") +
              theme_minimal() +
              theme(axis.text.x = element_blank(),
                    axis.ticks.x = element_blank())
            
            ggsave(file.path(output_path, "icu_los_boxplot.png"), 
                   p3, width = 6, height = 8, dpi = 300)
          }
          
          cat("Visualizations saved to", output_path, "\n")
        }
        ''')
    
    def _python_main_block(self) -> str:
        return textwrap.dedent('''
        def main():
            """Main analysis execution"""
            
            print("Starting CLIF Outcomes Analysis...")
            print(f"Data path: {DATA_PATH}")
            print(f"Output path: {OUTPUT_PATH}")
            
            # Initialize cohort builder
            cohort_builder = CohortBuilder(DATA_PATH)
            
            # Define cohort criteria
            criteria = {
                'age_range': {'min': 18, 'max': 80},
                'require_mechanical_ventilation': True,
                'exclude_readmissions': True
            }
            
            # Build cohort
            print("\\nBuilding cohort...")
            cohort = cohort_builder.build_cohort(criteria)
            print(f"Cohort size: {len(cohort)} hospitalizations")
            
            # Initialize outcomes analyzer
            analyzer = OutcomesAnalyzer(cohort_builder.tables)
            
            # Analyze outcomes
            print("\\nAnalyzing outcomes...")
            results = {}
            
            # Mortality analysis
            results['mortality'] = analyzer.analyze_mortality(cohort)
            print(f"Mortality rate: {results['mortality']['rate']:.1%}")
            
            # ICU LOS analysis
            results['icu_los'] = analyzer.analyze_icu_los(cohort)
            print(f"ICU LOS: {results['icu_los']['median']:.1f} days (median)")
            
            # Save results
            results_file = OUTPUT_PATH / 'analysis_results.json'
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            print(f"\\nResults saved to {results_file}")
            
            # Create visualizations
            create_outcomes_visualizations(results, OUTPUT_PATH)
            
            print("\\nAnalysis complete!")
        
        
        if __name__ == "__main__":
            main()
        ''')
    
    def generate_validation_script(self, analysis_id: str, 
                                 target_sites: List[str]) -> str:
        """Generate validation script for multi-site execution"""
        
        script = textwrap.dedent(f'''
        """
        Multi-Site Validation Script
        Analysis ID: {analysis_id}
        Target Sites: {', '.join(target_sites)}
        
        This script replicates the analysis across multiple CLIF sites.
        Each site runs this script locally on their data.
        """
        
        import hashlib
        import json
        from pathlib import Path
        
        ANALYSIS_ID = "{analysis_id}"
        SITE_ID = "YOUR_SITE_ID"  # Update with your site identifier
        
        # Run the main analysis
        exec(open("clif_analysis_script.py").read())
        
        # Generate site-specific results hash
        with open(OUTPUT_PATH / 'analysis_results.json', 'r') as f:
            results = json.load(f)
        
        # Add site identifier
        results['site_id'] = SITE_ID
        results['analysis_id'] = ANALYSIS_ID
        
        # Create summary for sharing (no patient-level data)
        summary = {{
            'site_id': SITE_ID,
            'analysis_id': ANALYSIS_ID,
            'cohort_size': results['mortality']['total'],
            'mortality_rate': results['mortality']['rate'],
            'mortality_ci': results['mortality']['ci_95'],
            'icu_los_median': results['icu_los']['median'],
            'icu_los_iqr': [results['icu_los']['q1'], results['icu_los']['q3']]
        }}
        
        # Save shareable summary
        summary_file = OUTPUT_PATH / f'summary_{{SITE_ID}}_{{ANALYSIS_ID}}.json'
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\\nSite summary saved to {{summary_file}}")
        print("This summary can be safely shared for multi-site analysis.")
        ''')
        
        return script
    
    def _generate_python_regression(self, config: Dict[str, Any]) -> str:
        """Generate Python code for regression analysis"""
        
        outcome = config['outcome']
        predictors = config['predictors']
        model_type = config['model_type']
        interaction_terms = config.get('interaction_terms', [])
        
        code = f"""
# Regression Analysis: {model_type.title()} Model
# Outcome: {outcome}
# Predictors: {', '.join(predictors)}

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# Prepare data
predictors = {predictors}
df_model = cohort[predictors + ['{outcome}']].dropna()

X = df_model[predictors]
y = df_model['{outcome}']
"""
        
        if interaction_terms:
            code += f"""
# Add interaction terms
interaction_terms = {interaction_terms}
for term in interaction_terms:
    if '*' in term:
        parts = term.split('*')
        df_model[term] = df_model[parts[0].strip()] * df_model[parts[1].strip()]
        X[term] = df_model[term]
"""
        
        if model_type == 'linear':
            code += """
# Fit linear regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

model = LinearRegression()
model.fit(X, y)

# Results
print("Linear Regression Results")
print("=" * 40)
print(f"R-squared: {r2_score(y, model.predict(X)):.4f}")
print("\\nCoefficients:")
for pred, coef in zip(X.columns, model.coef_):
    print(f"  {pred}: {coef:.4f}")
print(f"  Intercept: {model.intercept_:.4f}")
"""
        
        elif model_type == 'logistic':
            code += """
# Fit logistic regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, classification_report

model = LogisticRegression(max_iter=1000)
model.fit(X, y)

# Results
y_pred_proba = model.predict_proba(X)[:, 1]
print("Logistic Regression Results")
print("=" * 40)
print(f"AUC: {roc_auc_score(y, y_pred_proba):.4f}")
print("\\nCoefficients (log odds):")
for pred, coef in zip(X.columns, model.coef_[0]):
    print(f"  {pred}: {coef:.4f} (OR: {np.exp(coef):.2f})")
print(f"  Intercept: {model.intercept_[0]:.4f}")
"""
        
        return code
    
    def _generate_r_regression(self, config: Dict[str, Any]) -> str:
        """Generate R code for regression analysis"""
        
        outcome = config['outcome']
        predictors = config['predictors']
        model_type = config['model_type']
        
        formula = f"{outcome} ~ " + " + ".join(predictors)
        
        if config.get('interaction_terms'):
            for term in config['interaction_terms']:
                formula += f" + {term}"
        
        code = f"""
# Regression Analysis: {model_type.title()} Model
# Formula: {formula}
"""
        
        if model_type == 'linear':
            code += f"""
# Fit linear model
model <- lm({formula}, data = cohort)
summary(model)

# Diagnostics
par(mfrow = c(2, 2))
plot(model)
"""
        
        elif model_type == 'logistic':
            code += f"""
# Fit logistic regression
model <- glm({formula}, data = cohort, family = binomial())
summary(model)

# Odds ratios
exp(coef(model))
"""
        
        elif model_type == 'cox':
            code += f"""
# Fit Cox proportional hazards model
library(survival)
model <- coxph(Surv(los_days, {outcome}) ~ {' + '.join(predictors)}, data = cohort)
summary(model)
"""
        
        return code